{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-OkPm0QpmMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install imgaug --upgrade\n",
        "# !pip install albumentations --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ffAxO4CRaET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Eg-7kjwdB6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Drive if on Colab\n",
        "on_colab = True\n",
        "if on_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  \n",
        "  FOLDERNAME = 'chow chow 231n/trainer/'\n",
        "  assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "  import sys\n",
        "  sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "  %cd drive/My\\ Drive/$FOLDERNAME/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMkeOZ_RaEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import util\n",
        "import model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import sklearn\n",
        "\n",
        "from os.path import isfile \n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import pathlib"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UGraIO7S15c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define paths to data\n",
        "d = '../data/'\n",
        "dirs = {\n",
        "    'imgs_val':     d + 'val_data/',\n",
        "    'imgs_test':    d + \"test_data/\",\n",
        "    'lmdb_val':  d + 'val_lmdb',\n",
        "    'lmdb_test': d + 'test_lmdb'\n",
        "}\n",
        "\n",
        "files = {\n",
        "    'val_pkl':      d + \"lmdb_val_out.pkl\",\n",
        "    'test_pkl':     d + \"lmdb_test_out.pkl\",\n",
        "    'classes_pkl':  d + \"classes1M.pkl\",\n",
        "    'rvocab_pkl':   d + \"vocab.txt\",\n",
        "    'pt_pkl':       d + 'partition.pkl', # image ids\n",
        "    'lb_pkl':       d + 'labels.pkl', # labels\n",
        "    'ingr_pkl':     d + 'ingredients.pkl', # ingredient names\n",
        "    # 'cl_pkl':       d + 'classes.pkl', # class names\n",
        "}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2VS5YnjakiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0d9a0ea-6dce-473b-a635-9726cbbfbf98"
      },
      "source": [
        "# Read LMDB into pkl\n",
        "# TODO: add train dir, out file\n",
        "if not (isfile(files['val_pkl']) and isfile(files['test_pkl'])):\n",
        "    print(\"LMDBs processing into pkls\")\n",
        "    \n",
        "    lmdb_val_out = util.read_lmdb(dirs['lmdb_val'])\n",
        "    pickle.dump(lmdb_val_out, open(files['val_pkl'], 'wb'))\n",
        "    \n",
        "    lmdb_test_out = util.read_lmdb(dirs['lmdb_test'])\n",
        "    pickle.dump(lmdb_test_out, open(files['test_pkl'], 'wb'))\n",
        "else:\n",
        "    print(\"LMDBs already saved as pkls\")\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LMDBs already saved as pkls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gswxY47RFNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d9fe025-5178-4620-9aa5-cef1120799eb"
      },
      "source": [
        "# Load data\n",
        "if not (isfile(files['pt_pkl']) and isfile(files['lb_pkl']) and isfile(files['ingr_pkl'])):\n",
        "    print(\"Datasets processing for the 1st time into pkls\")\n",
        "    partition, labels, ingrs = util.load_data(dirs, files)\n",
        "    \n",
        "    pickle.dump(partition, open(files['pt_pkl'], \"wb\"))\n",
        "    pickle.dump(labels, open(files['lb_pkl'], \"wb\"))\n",
        "    pickle.dump(ingrs, open(files['ingr_pkl'], \"wb\"))\n",
        "    print(\"Datasets loaded\")\n",
        "else:\n",
        "    partition = pickle.load(open(files['pt_pkl'], \"rb\"))\n",
        "    labels = pickle.load(open(files['lb_pkl'], \"rb\"))\n",
        "    ingrs = pickle.load(open(files['ingr_pkl'], \"rb\"))\n",
        "    print(\"Datasets loaded from pkls\")\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets loaded from pkls\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_iz--kdqHhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create data generators\n",
        "data_params = {'dim': (224,224),\n",
        "              'batch_size': 2,\n",
        "              'n_ingrs': len(ingrs),\n",
        "              'n_channels': 3,\n",
        "              'shuffle': True}\n",
        "\n",
        "image_dir_tr = dirs['imgs_val']\n",
        "image_dir_val = dirs['imgs_test']\n",
        "\n",
        "gen_tr = model.DataGenerator(partition['train'], labels, image_dir_tr, **data_params)\n",
        "gen_val = model.DataGenerator(partition['validation'], labels, image_dir_val, **data_params)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlmAE6q9RaEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check generator and fetching speed\n",
        "X, y = gen_tr.__getitem__(0)\n",
        "for i, img in enumerate(X):\n",
        "    ia.imshow(img)\n",
        "    print(y[i])\n",
        "    break\n",
        "\n",
        "X, y = gen_val.__getitem__(0)\n",
        "for i, img in enumerate(X):\n",
        "    ia.imshow(img)\n",
        "    print(y[i])\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUUroCVXRaEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7ce8505-88be-40a9-fe5f-62f1c04468b6"
      },
      "source": [
        "# Name experiment\n",
        "trial_name = 'test'\n",
        "today = datetime.now().strftime('%m_%d')\n",
        "trial_ct = len(list(pathlib.Path('logs/').rglob(today+'*/'))) + 1\n",
        "exp_name =  '{}_{}_{}'.format(today, trial_ct, trial_name)\n",
        "logdir = 'logs/' + exp_name\n",
        "print('Running experiment ', exp_name)\n",
        "\n",
        "# Stage 1 training\n",
        "# Choose parameters for initializing the last layer\n",
        "init_params = {\n",
        "    'lr': 1e-2,\n",
        "    'input_shape': (*data_params['dim'], data_params['n_channels']),\n",
        "    'num_ingrs': len(ingrs),\n",
        "    'eps': 10, \n",
        "}\n",
        "\n",
        "# Stage 2 training\n",
        "# Choose parameters for transfer learning on the pre-trained model\n",
        "best_init_name = '{}_{}_{}'.format('08_27', '2', 'testtest') # select stage 1 weights to use\n",
        "tl_params = {\n",
        "    'lr': 1e-5,\n",
        "    'num_unfreeze': 4, # num layers to unfreeze from top of pre-trained model\n",
        "    'init_path': '{}/{}/{}'.format('logs', best_init_name, 'best_epoch_model.h5'),\n",
        "    'eps': 100,\n",
        "}\n",
        "\n",
        "# Load model\n",
        "is_init = True # choose stage of training\n",
        "if is_init:\n",
        "    print('Loaded stage 1 model')\n",
        "    nn = model.create_init_model(init_params)\n",
        "    eps = init_params['eps']\n",
        "else:\n",
        "    print('Loaded stage 2 model')\n",
        "    nn = model.create_tl_model(tl_params)\n",
        "    eps = tl_params['eps']"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running experiment  08_27_7_test\n",
            "Loaded stage 1 model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CceOJb_HALbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define callbacks\n",
        "lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: lr + 0.02 * (0.5 ** (1 + epoch)),\n",
        "    verbose=True)\n",
        "\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "class MetricsHistory(Callback):\n",
        "    def __init__(self):\n",
        "        self.best_score = -1\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        tr_score = logs['f1_ml']\n",
        "        val_score = logs['val_f1_ml']\n",
        "\n",
        "        print('\\n\\nTrain F1: {:2f} \\nVal F1:   {:2f}\\n\\n'.format(tr_score, val_score))\n",
        "        \n",
        "        if val_score > self.best_score:\n",
        "            print(\"\\nBetter validation score! Saving model ...\")\n",
        "            if not os.path.exists(logdir):\n",
        "                os.makedirs(logdir)\n",
        "            self.model.save(logdir + '/best_epoch_model.h5')\n",
        "            self.best_score = val_score\n",
        "\n",
        "metrics_cb = MetricsHistory()"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDG9qxSvRaEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize training\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE2raSRpRaEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "history = nn.fit(gen_tr, epochs=eps, validation_data=gen_val, \n",
        "                 callbacks=[tensorboard_cb, metrics_cb])\n",
        "\n",
        "# use_multiprocessing=True, workers=6, \n",
        "# lr_decay_cb, validation_steps=val_steps, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAoIE0H1RaEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export\n",
        "nn.save(logdir + \"/last_epoch_model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP6QDxhDRaEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate predictions\n",
        "X_s, y_s = gen_val.__getitem__(1)\n",
        "for i, pred in enumerate(nn.predict(X_s)):    \n",
        "    truth = y_s[i]\n",
        "    img = X_s[i]\n",
        "    \n",
        "    true_class_id = np.where(truth == 1)[0]\n",
        "    pred_class_id = np.where(pred > 1e-9)[0]\n",
        "    \n",
        "    print(\"Image \", i)\n",
        "    print(\"True: \", [ingrs[x] for x in true_class_id])\n",
        "    print(\"Predicted: \", [ingrs[x] for x in pred_class_id])\n",
        "    print()\n",
        "    print(true_class_id)\n",
        "    print(pred_class_id)\n",
        "    print(\"Predicted logit: \", pred[pred_class_id])\n",
        "    ia.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}