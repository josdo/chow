{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-OkPm0QpmMn"
   },
   "outputs": [],
   "source": [
    "# !pip install imgaug --upgrade\n",
    "# !pip install albumentations --upgrade\n",
    "# !pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ffAxO4CRaET"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Eg-7kjwdB6D"
   },
   "outputs": [],
   "source": [
    "# Mount Drive if on Colab\n",
    "on_colab = False\n",
    "if on_colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive', force_remount=True)\n",
    "  \n",
    "  FOLDERNAME = 'chow chow/trainer/'\n",
    "  assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "  import sys\n",
    "  sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "  %cd drive/My\\ Drive/$FOLDERNAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iMkeOZ_RaEX"
   },
   "outputs": [],
   "source": [
    "import util\n",
    "import model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from os.path import isfile \n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UGraIO7S15c"
   },
   "outputs": [],
   "source": [
    "# Define paths to data\n",
    "d = '../data/'\n",
    "dirs = {\n",
    "    'imgs_train':     d + 'train_data/',\n",
    "    'imgs_val': d + 'val_data/',\n",
    "    'imgs_test':d + \"test_data/\",\n",
    "    'lmdb_train':d + 'train_lmdb',\n",
    "    'lmdb_val':  d + 'val_lmdb',\n",
    "    'lmdb_test': d + 'test_lmdb'\n",
    "}\n",
    "\n",
    "files = {\n",
    "    'train_pkl':    d + \"lmdb_train_out.pkl\",\n",
    "    'val_pkl':      d + \"lmdb_val_out.pkl\",\n",
    "    'test_pkl':     d + \"lmdb_test_out.pkl\",\n",
    "    'classes_pkl':  d + \"classes1M.pkl\",\n",
    "    'rvocab_pkl':   d + \"vocab.txt\",\n",
    "    'pt_pkl':       d + 'partition.pkl', # image ids\n",
    "    'lb_pkl':       d + 'labels.pkl', # labels\n",
    "    'ingr_pkl':     d + 'ingredients.pkl', # ingredient names\n",
    "    'ingr_id2id_pkl':   d + 'ingr_id2id.pkl', # ingredient old to new id\n",
    "    # 'cl_pkl':       d + 'classes.pkl', # class names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2VS5YnjakiT",
    "outputId": "0a4a2cdf-36d8-482d-e720-18306965b3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDBs already saved as pkls\n"
     ]
    }
   ],
   "source": [
    "# Read LMDB into pkl\n",
    "# TODO: add train dir, out file\n",
    "if not (isfile(files['train_pkl']) and isfile(files['val_pkl']) and isfile(files['test_pkl'])):\n",
    "    print(\"LMDBs processing into pkls\")\n",
    "    lmdb_train_out = util.read_lmdb(dirs['lmdb_train'])\n",
    "    pickle.dump(lmdb_train_out, open(files['train_pkl'], 'wb'))\n",
    "    \n",
    "    lmdb_val_out = util.read_lmdb(dirs['lmdb_val'])\n",
    "    pickle.dump(lmdb_val_out, open(files['val_pkl'], 'wb'))\n",
    "    \n",
    "    lmdb_test_out = util.read_lmdb(dirs['lmdb_test'])\n",
    "    pickle.dump(lmdb_test_out, open(files['test_pkl'], 'wb'))\n",
    "else:\n",
    "    print(\"LMDBs already saved as pkls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "# Allows memory usage > 15.5 GB (size of labels array during util.load_data)\n",
    "# From https://stackoverflow.com/a/61963727, https://stackoverflow.com/a/57511555\n",
    "!echo 1 | sudo tee /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0gswxY47RFNg",
    "outputId": "8c9c1aaa-bb1d-4a93-add1-1559aefac3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets processing for the 1st time into pkls\n",
      "Collecting all image paths in ../data/train_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/619408 [00:00<1:26:51, 118.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting completed in 1.97 minutes\n",
      "619408 original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 619408/619408 [1:14:03<00:00, 139.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383697 usable labeled images\n",
      "Collecting all image paths in ../data/val_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 84/133842 [00:00<02:39, 836.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting completed in 1.46 minutes\n",
      "133842 original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133842/133842 [02:20<00:00, 954.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82079 usable labeled images\n",
      "Collecting all image paths in ../data/test_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/134286 [00:00<02:59, 749.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting completed in 1.55 minutes\n",
      "134286 original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134286/134286 [02:44<00:00, 815.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82352 usable labeled images\n",
      "# unique ingredients: 3784\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "if not (isfile(files['pt_pkl']) and isfile(files['lb_pkl']) and isfile(files['ingr_pkl'])):\n",
    "    print(\"Datasets processing for the 1st time into pkls\")\n",
    "    partition, labels, ingrs = util.load_data(dirs, files)\n",
    "    \n",
    "    pickle.dump(partition, open(files['pt_pkl'], \"wb\"))\n",
    "    pickle.dump(labels, open(files['lb_pkl'], \"wb\"))\n",
    "    pickle.dump(ingrs, open(files['ingr_pkl'], \"wb\"))\n",
    "    print(\"Datasets loaded\")\n",
    "else:\n",
    "    partition = pickle.load(open(files['pt_pkl'], \"rb\"))\n",
    "    labels = pickle.load(open(files['lb_pkl'], \"rb\"))\n",
    "    ingrs = pickle.load(open(files['ingr_pkl'], \"rb\"))\n",
    "    print(\"Datasets loaded from pkls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_iz--kdqHhE"
   },
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "data_params = {'dim': (224,224),\n",
    "              'batch_size': 2,\n",
    "              'n_ingrs': len(ingrs),\n",
    "              'n_channels': 3,\n",
    "              'shuffle': True}\n",
    "\n",
    "image_dir_tr = dirs['imgs_val']\n",
    "image_dir_val = dirs['imgs_test']\n",
    "\n",
    "gen_tr = model.DataGenerator(partition['train'], labels, image_dir_tr, **data_params)\n",
    "gen_val = model.DataGenerator(partition['validation'], labels, image_dir_val, **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "HlmAE6q9RaEd",
    "outputId": "7e429132-83d3-4142-b5cf-716ac77ceb40"
   },
   "outputs": [],
   "source": [
    "# Check generator and fetching speed\n",
    "X, y = gen_tr.__getitem__(0)\n",
    "for i, img in enumerate(X):\n",
    "    ia.imshow(img)\n",
    "    print(y[i])\n",
    "    break\n",
    "\n",
    "X, y = gen_val.__getitem__(0)\n",
    "for i, img in enumerate(X):\n",
    "    ia.imshow(img)\n",
    "    print(y[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUUroCVXRaEg"
   },
   "outputs": [],
   "source": [
    "# Change for each experiment\n",
    "trial_name = 'stage1_resnet'\n",
    "is_init = True # choose stage of training\n",
    "model_name = 'densenet'\n",
    "best_init_name = '{}_{}_{}'.format('08_28', '2', 'try_densenet') # select stage 1 weights to use\n",
    "\n",
    "# Name experiment\n",
    "today = datetime.now().strftime('%m_%d')\n",
    "trial_ct = len(list(pathlib.Path('logs/').rglob(today+'*/'))) + 1\n",
    "exp_name =  '{}_{}_{}'.format(today, trial_ct, trial_name)\n",
    "logdir = 'logs/' + exp_name\n",
    "print('Running experiment ', exp_name)\n",
    "\n",
    "# Stage 1 training\n",
    "# Choose parameters for initializing the last layer\n",
    "init_params = {\n",
    "    'model_name': model_name,\n",
    "    'lr': 1e-2,\n",
    "    'input_shape': (*data_params['dim'], data_params['n_channels']),\n",
    "    'num_ingrs': len(ingrs),\n",
    "    'eps': 10, \n",
    "}\n",
    "\n",
    "# Stage 2 training\n",
    "# Choose parameters for transfer learning on the pre-trained model\n",
    "tl_params = {\n",
    "    'lr': 1e-5,\n",
    "    'num_unfreeze': 4, # num layers to unfreeze from top of pre-trained model\n",
    "    'init_path': '{}/{}/{}'.format('logs', best_init_name, 'best_epoch_model.h5'),\n",
    "    'eps': 100,\n",
    "}\n",
    "\n",
    "# Load model\n",
    "if is_init:\n",
    "    print('Loaded stage 1 model')\n",
    "    nn = model.create_init_model(init_params)\n",
    "    eps = init_params['eps']\n",
    "else:\n",
    "    print('Loaded stage 2 model')\n",
    "    nn = model.create_tl_model(tl_params)\n",
    "    eps = tl_params['eps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CceOJb_HALbH"
   },
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "lr_decay_cb = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: lr + 0.02 * (0.5 ** (1 + epoch)),\n",
    "    verbose=True)\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "class MetricsHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.best_score = -1\n",
    "        self.start_time = None\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Report train and val metric\n",
    "        tr_score = logs['f1_ml']\n",
    "        val_score = logs['val_f1_ml']\n",
    "        print(\"\\n\\nTrain F1: {:2f} \\nVal F1:   {:2f}\".format(tr_score, val_score))\n",
    "        \n",
    "        # Report time taken to complete this epoch\n",
    "        elapsed = (time.time() - self.start_time) / 60\n",
    "        print(\"Epoch finshed in {:.1f} minutes\".format(elapsed))\n",
    "\n",
    "        # Save model if better\n",
    "        if val_score > self.best_score:\n",
    "            print(\"Better validation score! Saving model ...\")\n",
    "            if not os.path.exists(logdir):\n",
    "                os.makedirs(logdir)\n",
    "            self.model.save(logdir + '/best_epoch_model.h5')\n",
    "            self.best_score = val_score\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "metrics_cb = MetricsHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDG9qxSvRaEi"
   },
   "outputs": [],
   "source": [
    "# Visualize training\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nE2raSRpRaEk",
    "outputId": "7add337d-0306-4b56-f8e8-ee62d3f10101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 533.9206 - f1_ml: 2.7632e-04 - prec_ml: 2.7632e-04 - recall_ml: 2.7632e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 642.9612 - f1_ml: 3.5922e-04 - prec_ml: 3.7303e-04 - recall_ml: 3.5922e-04\n",
      "\n",
      "Train F1: 0.000359 \n",
      "Val F1:   0.000113\n",
      "Epoch finshed in 0.1 minutes\n",
      "Better validation score! Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 10s 1s/step - loss: 642.9612 - f1_ml: 3.5922e-04 - prec_ml: 3.7303e-04 - recall_ml: 3.5922e-04 - val_loss: 1383.1191 - val_f1_ml: 1.1257e-04 - val_prec_ml: 1.0746e-04 - val_recall_ml: 1.2281e-04\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 646.6033 - f1_ml: 4.2369e-04 - prec_ml: 4.4211e-04 - recall_ml: 4.1448e-04\n",
      "\n",
      "Train F1: 0.000424 \n",
      "Val F1:   0.000143\n",
      "Epoch finshed in 0.1 minutes\n",
      "Better validation score! Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 9s 880ms/step - loss: 646.6033 - f1_ml: 4.2369e-04 - prec_ml: 4.4211e-04 - recall_ml: 4.1448e-04 - val_loss: 1422.6389 - val_f1_ml: 1.4328e-04 - val_prec_ml: 1.3816e-04 - val_recall_ml: 1.5351e-04\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 693.4374 - f1_ml: 3.2237e-04 - prec_ml: 3.1777e-04 - recall_ml: 3.3158e-04\n",
      "\n",
      "Train F1: 0.000322 \n",
      "Val F1:   0.000072\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 788ms/step - loss: 693.4374 - f1_ml: 3.2237e-04 - prec_ml: 3.1777e-04 - recall_ml: 3.3158e-04 - val_loss: 1488.9351 - val_f1_ml: 7.1638e-05 - val_prec_ml: 6.1404e-05 - val_recall_ml: 9.2106e-05\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 699.1080 - f1_ml: 3.5922e-04 - prec_ml: 3.5922e-04 - recall_ml: 3.5922e-04\n",
      "\n",
      "Train F1: 0.000359 \n",
      "Val F1:   0.000133\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 825ms/step - loss: 699.1080 - f1_ml: 3.5922e-04 - prec_ml: 3.5922e-04 - recall_ml: 3.5922e-04 - val_loss: 1573.4800 - val_f1_ml: 1.3304e-04 - val_prec_ml: 1.5351e-04 - val_recall_ml: 1.2281e-04\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 741.7872 - f1_ml: 3.1316e-04 - prec_ml: 3.1777e-04 - recall_ml: 3.1777e-04\n",
      "\n",
      "Train F1: 0.000313 \n",
      "Val F1:   0.000041\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 789ms/step - loss: 741.7872 - f1_ml: 3.1316e-04 - prec_ml: 3.1777e-04 - recall_ml: 3.1777e-04 - val_loss: 1571.1392 - val_f1_ml: 4.0936e-05 - val_prec_ml: 4.6053e-05 - val_recall_ml: 4.6053e-05\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 752.8360 - f1_ml: 3.9606e-04 - prec_ml: 4.0066e-04 - recall_ml: 4.0066e-04\n",
      "\n",
      "Train F1: 0.000396 \n",
      "Val F1:   0.000082\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 778ms/step - loss: 752.8360 - f1_ml: 3.9606e-04 - prec_ml: 4.0066e-04 - recall_ml: 4.0066e-04 - val_loss: 1704.2991 - val_f1_ml: 8.1872e-05 - val_prec_ml: 7.6755e-05 - val_recall_ml: 9.2106e-05\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 761.1293 - f1_ml: 3.5922e-04 - prec_ml: 3.8685e-04 - recall_ml: 3.4540e-04\n",
      "\n",
      "Train F1: 0.000359 \n",
      "Val F1:   0.000072\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 780ms/step - loss: 761.1293 - f1_ml: 3.5922e-04 - prec_ml: 3.8685e-04 - recall_ml: 3.4540e-04 - val_loss: 1705.0100 - val_f1_ml: 7.1638e-05 - val_prec_ml: 7.6755e-05 - val_recall_ml: 7.6755e-05\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 790.4238 - f1_ml: 3.5000e-04 - prec_ml: 3.5922e-04 - recall_ml: 3.4540e-04\n",
      "\n",
      "Train F1: 0.000350 \n",
      "Val F1:   0.000092\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 773ms/step - loss: 790.4238 - f1_ml: 3.5000e-04 - prec_ml: 3.5922e-04 - recall_ml: 3.4540e-04 - val_loss: 1820.4978 - val_f1_ml: 9.2106e-05 - val_prec_ml: 9.2106e-05 - val_recall_ml: 1.0746e-04\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 834.5460 - f1_ml: 3.9606e-04 - prec_ml: 4.0066e-04 - recall_ml: 4.0066e-04\n",
      "\n",
      "Train F1: 0.000396 \n",
      "Val F1:   0.000041\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 780ms/step - loss: 834.5460 - f1_ml: 3.9606e-04 - prec_ml: 4.0066e-04 - recall_ml: 4.0066e-04 - val_loss: 1886.2642 - val_f1_ml: 4.0936e-05 - val_prec_ml: 3.0702e-05 - val_recall_ml: 6.1404e-05\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 857.6038 - f1_ml: 3.9606e-04 - prec_ml: 4.1448e-04 - recall_ml: 3.8685e-04\n",
      "\n",
      "Train F1: 0.000396 \n",
      "Val F1:   0.000082\n",
      "Epoch finshed in 0.1 minutes\n",
      "\n",
      "\n",
      "\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 857.6038 - f1_ml: 3.9606e-04 - prec_ml: 4.1448e-04 - recall_ml: 3.8685e-04 - val_loss: 1883.5642 - val_f1_ml: 8.1872e-05 - val_prec_ml: 7.6755e-05 - val_recall_ml: 9.2106e-05\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = nn.fit(gen_tr, epochs=eps, validation_data=gen_val, \n",
    "                 callbacks=[tensorboard_cb, metrics_cb])\n",
    "\n",
    "# use_multiprocessing=True, workers=6, \n",
    "# lr_decay_cb, validation_steps=val_steps, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAoIE0H1RaEn"
   },
   "outputs": [],
   "source": [
    "# Export\n",
    "nn.save(logdir + \"/last_epoch_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kP6QDxhDRaEs"
   },
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "X_s, y_s = gen_val.__getitem__(1)\n",
    "for i, pred in enumerate(nn.predict(X_s)):    \n",
    "    truth = y_s[i]\n",
    "    img = X_s[i]\n",
    "    \n",
    "    true_class_id = np.where(truth == 1)[0]\n",
    "    pred_class_id = np.where(pred > 1e-9)[0]\n",
    "    \n",
    "    print(\"Image \", i)\n",
    "    print(\"True: \", [ingrs[x] for x in true_class_id])\n",
    "    print(\"Predicted: \", [ingrs[x] for x in pred_class_id])\n",
    "    print()\n",
    "    print(true_class_id)\n",
    "    print(pred_class_id)\n",
    "    print(\"Predicted logit: \", pred[pred_class_id])\n",
    "    ia.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
